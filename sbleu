#!/usr/bin/env python3
"""
Standardized, reportable BLEU script.
Based on Rico Sennrich's `multi-bleu-detok.perl`.
Knows all the standard test sets; downloads and tokenizes them for you.

Why use this version of BLEU?
- It automatically downloads and manages common test sets
- It properly computes scores on detokenized outputs, using its own tokenization
- It produces the same values as (semi-)official scripts from WMT
- It produces a short version string that facilitates cross-lab comparisons
- It outputs the BLEU score without the comma, so you don't have to remove it with 'sed'
  (Looking at you, multi-bleu.perl)

en-de+m.nist+lc
"""

VERSION = '0.1'

import re
import os
import sys
import math
import tarfile
import urllib.request, urllib.parse
import argparse

from collections import defaultdict, namedtuple

# Where to store downloaded test sets.
# Define the environment variable $SACREBLEU, or use the default of ~/.sacrebleu.
SACREBLEU = os.environ.get('SACREBLEU',os.path.join(os.environ.get('HOME'), '.sacrebleu'))

# This defines data locations.
# At the top level are test sets.
# Beneath each test set, we define the location to download the test data.
# The other keys are each language pair contained in the tarball, and the respective locations of the source and reference data within each.
# Many of these are *.sgm files, which are processed to produced plain text that can be used by this script.
# The canonical location of unpacked, processed data is $SACREBLEU/TEST/PAIR/test.{SOURCE,TARGET}
data = {
    'wmt17': {
        'data': 'http://data.statmt.org/wmt17/translation-task/test.tgz',
        'cs-en': ['test/newstest2017-csen-src.cs.sgm', 'test/newstest2017-csen-ref.en.sgm'],
        'en-cs': ['test/newstest2017-encs-src.en.sgm', 'test/newstest2017-encs-ref.cs.sgm'],
        'de-en': ['test/newstest2017-deen-src.de.sgm', 'test/newstest2017-deen-ref.en.sgm'],
        'en-de': ['test/newstest2017-ende-src.en.sgm', 'test/newstest2017-ende-ref.de.sgm'],
        'en-fi': ['test/newstest2017-enfi-src.en.sgm', 'test/newstest2017-enfi-ref.fi.sgm'],
#        'en-fi': ['test/newstestB2017-enfi-src.en.sgm', 'test/newstestB2017-enfi-ref.fi.sgm'],
        'en-lv': ['test/newstest2017-enlv-src.en.sgm', 'test/newstest2017-enlv-ref.lv.sgm'],
        'en-ru': ['test/newstest2017-enru-src.en.sgm', 'test/newstest2017-enru-ref.ru.sgm'],
        'en-tr': ['test/newstest2017-entr-src.en.sgm', 'test/newstest2017-entr-ref.tr.sgm'],
        'en-zh': ['test/newstest2017-enzh-src.en.sgm', 'test/newstest2017-enzh-ref.zh.sgm'],
        'fi-en': ['test/newstest2017-fien-src.fi.sgm', 'test/newstest2017-fien-ref.en.sgm'],
#        'fi-en': ['test/newstestB2017-fien-src.fi.sgm', 'test/newstestB2017-fien-ref.en.sgm'],
        'lv-en': ['test/newstest2017-lven-ref.en.sgm', 'test/newstest2017-lven-src.lv.sgm'],
        'ru-en': ['test/newstest2017-ruen-src.ru.sgm', 'test/newstest2017-ruen-ref.en.sgm'],
        'tr-en': ['test/newstest2017-tren-ref.en.sgm', 'test/newstest2017-tren-src.tr.sgm'],
        'zh-en': ['test/newstest2017-zhen-src.zh.sgm', 'test/newstest2017-zhen-ref.en.sgm'],
    },
    'wmt16': {
        'data': 'http://data.statmt.org/wmt16/translation-task/test.tgz',
        'cs-en': ['test/newstest2016-csen-src.cs.sgm', 'test/newstest2016-csen-ref.en.sgm'],
        'de-en': ['test/newstest2016-deen-src.de.sgm', 'test/newstest2016-deen-ref.en.sgm'],
        'en-cs': ['test/newstest2016-encs-src.en.sgm', 'test/newstest2016-encs-ref.cs.sgm'],
        'en-de': ['test/newstest2016-ende-src.en.sgm', 'test/newstest2016-ende-ref.de.sgm'],
        'en-fi': ['test/newstest2016-enfi-src.en.sgm', 'test/newstest2016-enfi-ref.fi.sgm'],
#        'en-fi': ['test/newstestB2016-enfi-src.en.sgm', 'test/newstestB2016-enfi-ref.fi.sgm'],
        'en-ro': ['test/newstest2016-enro-src.en.sgm', 'test/newstest2016-enro-ref.ro.sgm'],
        'en-ru': ['test/newstest2016-enru-src.en.sgm', 'test/newstest2016-enru-ref.ru.sgm'],
        'en-tr': ['test/newstest2016-entr-src.en.sgm', 'test/newstest2016-entr-ref.tr.sgm'],
        'fi-en': ['test/newstest2016-fien-src.fi.sgm', 'test/newstest2016-fien-ref.en.sgm'],
        'ro-en': ['test/newstest2016-roen-src.ro.sgm', 'test/newstest2016-roen-ref.en.sgm'],
        'ru-en': ['test/newstest2016-ruen-src.ru.sgm', 'test/newstest2016-ruen-ref.en.sgm'],
        'tr-en': ['test/newstest2016-tren-src.tr.sgm', 'test/newstest2016-tren-ref.en.sgm'],
    },
    'wmt15': {
        'data': 'http://statmt.org/wmt15/test.tgz',
    },
    'wmt14': {
        'data': 'http://statmt.org/wmt14/test-filtered.tgz',
        'en-de': [ ]
    },
    'wmt14full': {
        'data': 'http://statmt.org/wmt14/test-full.tgz',
    },
    'wmt13': {
        'data': 'http://statmt.org/wmt13/test.tgz',
    },
    'wmt12': {
        'data': 'http://statmt.org/wmt12/test.tgz',
    },
    'wmt11': {
        'data': 'http://statmt.org/wmt11/test.tgz',
    },
    'wmt10': {
        'data': 'http://statmt.org/wmt10/test.tgz',
    },
    'wmt09': {
        'data': 'http://statmt.org/wmt09/test.tgz',
    },
    'wmt08': {
        'data': 'http://statmt.org/wmt08/test.tgz',
    }
}


def tokenize(line):
    norm = line

    # language-independent part:
    norm = norm.replace('<skipped>', '')
    norm = norm.replace('-\n', '')
    norm = norm.replace('\n', ' ')
    norm = norm.replace('&quot;', '"')
    norm = norm.replace('&amp;', '"')
    norm = norm.replace('&ltt;', '"')
    norm = norm.replace('&gt;', '"')
    
    # language-dependent part (assuming Western languages):
    norm = " {} ".format(norm)
    norm = re.sub(r'([\{-\~\[-\` -\&\(-\+\:-\@\/])', ' \\1 ', norm)
    norm = re.sub(r'([^0-9])([\.,])', '\\1 \\2 ', norm) # tokenize period and comma unless preceded by a digit
    norm = re.sub(r'([\.,])([^0-9])', ' \\1 \\2', norm) # tokenize period and comma unless followed by a digit
    norm = re.sub(r'([0-9])(-)', '\\1 \\2 ', norm) # tokenize dash when preceded by a digit
    norm = re.sub(r'\s+', ' ', norm) # one space only between words
    norm = re.sub(r'^\s+', '', norm) # no leading space
    norm = re.sub(r'\s+$', '', norm) # no trailing space

    return norm

def lowercase(s):
    return s.lower()

def metric():
    pass

funcs = {
    'lc': lowercase,
    'met': metric,
    'tok': tokenize
}

def _read(file):
    if file.endswith('.gz'):
        return gzip.open(file, 'rt')
    return open(file, 'rt')


def my_log(num):
    """Floors the log function

    :param num: the number
    :return: log(num) floored to a very low number
    """

    if num == 0.0:
        return -9999999999
    return math.log(num)


def build_signature(args):
    sig = '{}.{}-{}'.format(VERSION, args.test_set, args.langpair)
    
    if args.lc is not None:
        sig += "+lc"

    return sig

def extract_ngrams(line, max=4):
    """Extracts all the ngrams (1 <= n <= 4) from a sequence of tokens.

    :param line: a segment containing a sequence of words
    :param max: collect n-grams from 1<=n<=max
    :return: a dictionary containing ngrams and counts
    """

    ngrams = defaultdict(int)
    tokens = line.split()
    for n in range(1, max+1):
        for i in range(0, len(tokens) - n + 1):
            ngram = ' '.join(tokens[i:i+n])
            ngrams[ngram] += 1

    return ngrams

def ref_stats(output, refs):
    ngrams = defaultdict(int)
    closest_diff = None
    closest_len = None
    for ref in refs:
        tokens = ref.split()
        reflen = len(tokens)
        diff = abs(len(output.split()) - reflen)
        if closest_diff is None or diff < closest_diff:
            closest_diff = diff
            closest_len = reflen
        elif diff == closest_diff:
            if reflen < closest_len:
                closest_len = len

        ngrams_ref = extract_ngrams(ref)
        for ngram in ngrams_ref.keys():
            ngrams[ngram] = max(ngrams[ngram], ngrams_ref[ngram])

    return ngrams, closest_diff, closest_len


def process_to_text(rawfile, txtfile):
    """Copies raw files to 
    :param rawfile: the input file (possibly SGML)
    :param txtfile: the plaintext file
    """

    if rawfile.endswith('.sgm') or rawfile.endswith('.sgml'):
        with _read(rawfile) as fin, open(txtfile, 'wt') as fout:
            for line in fin:
                if line.startswith('<seg '):
                    fout.write(re.sub(r'<seg.*?>(.*)</seg>.*?', '\\1', line))


def download_test_set(test_set, langpair=None):
    """Downloads the specified test to the system location specified by the SACREBLEU environment variable.
    :param test_set: the test set to download
    :param langpair: the language pair (needed for some datasets)
    :return: the file path, or None if no such dataset could be found
    """

    # if not data.has_key(test_set):
    #     return None
    
    dataset = data[test_set]['data']
    outdir = os.path.join(SACREBLEU, test_set)
    if not os.path.exists(os.path.dirname(outdir)):
        print("Creating", os.path.dirname(outdir), file=sys.stdout)
        os.makedirs(os.path.dirname(outdir))

    tarball = os.path.join(outdir, os.path.basename(dataset))
    if not os.path.exists(tarball):
        # TODO: check MD5sum
        print("Downloading {} to {}".format(dataset, tarball), file=sys.stdout)
        with urllib.request.urlopen(dataset) as f, open(tarball, 'wb') as out:
            out.write(f.read())

    rawdir = os.path.join(outdir, 'raw')
    print('Extracting {}'.format(tarball))
    tar = tarfile.open(tarball)
    tar.extractall(path=rawdir)

    src, tgt = langpair.split('-')
    languages = data[test_set].keys() if langpair is None else [langpair]
    for pair in languages:
        if pair == 'data':
            continue
        rawfile = os.path.join(rawdir, data[test_set][pair][0])
        outfile = os.path.join(outdir, '{}.src'.format(pair))
        process_to_text(rawfile, outfile)

        rawfile = os.path.join(rawdir, data[test_set][pair][1])
        outfile = os.path.join(outdir, '{}.ref'.format(pair))
        process_to_text(rawfile, outfile)


BLEU = namedtuple('BLEU', 'score, ngram1, ngram2, ngram3, ngram4, bp, sys_len, ref_len')

def bleu(instream, refstreams) -> BLEU:
    """Produces the BLEU scores along with its sufficient statistics from a source against one or more references.

    :param instream: the input stream, one segment per line
    :param refstreams: a list of reference streams
    :return: a BLEU object containing everything you'd want
    """

    fhs = [sys.stdin] + refstreams

    sys_len = 0
    ref_len = 0

    correct = defaultdict(int)
    total = defaultdict(int)

    for sentno, lines in enumerate(zip(*fhs)):
        if args.lc:
            lines = [x.lower() for x in lines]

        output, *refs = [tokenize(x.rstrip()) for x in lines]
    
        ref_ngrams, closest_diff, closest_len = ref_stats(output, refs)

        sys_len += len(output.split())
        ref_len += closest_len

        sys_ngrams = extract_ngrams(output)
        for ngram in sys_ngrams.keys():
            n = len(ngram.split())

            total[n] += sys_ngrams[ngram]
            correct[n] += min(sys_ngrams[ngram], ref_ngrams.get(ngram, 0))

    precisions  = [0, 0, 0, 0, 0]

    for n in range(1, 5):
        precisions[n] = 100. * correct[n] / total[n] if total.get(n) > 0 else 0.

    brevity_penalty = 1.0
    if sys_len < ref_len:
        brevity_penalty = math.exp(1 - ref_len / sys_len)

    bleu = 1. * brevity_penalty * math.exp(sum(map(my_log, precisions[1:])) / 4)

    return BLEU._make([bleu, *precisions[1:], brevity_penalty, sys_len, ref_len])


if __name__ == '__main__':

    arg_parser = argparse.ArgumentParser()
    arg_parser.add_argument('--test-set', '-t', type=str, default=None,
                            help='The test set to use')
    arg_parser.add_argument('--sig', default=None, type=str,
                            help='Signature string')
    arg_parser.add_argument('-lc', action='store_true', default=False,
                            help='Case-insensitive BLEU')
    arg_parser.add_argument('--json', action='store_true', default=False,
                            help='Output JSON instead of plain text')
    arg_parser.add_argument('--language-pair', '-l', dest='langpair', default='??-??',
                            help='source-target language pair (2-char ISO639-1 codes')
    arg_parser.add_argument('--download', type=str, default=None,
                            help='Just download a test set and quit')
    arg_parser.add_argument('refs', nargs='*', default=[],
                            help='references')
    args = arg_parser.parse_args()

    version_str = build_signature(args)

    if args.download:
        download_test_set(args.download, args.langpair)
        sys.exit(0)

    if args.test_set:
        download_test_set(args.test_set, args.langpair)

        refs = None
    else:        
        refs = args.refs
    
    # bleu, precisions, brevity_penalty, sys_len, ref_len = bleu(sys.stdin, [_read(x) for x in refs])
    bleu = bleu(sys.stdin, [_read(x) for x in refs])

    print('BLEU+{} = {:.2f} {:.1f}/{:.1f}/{:.1f}/{:.1f} (BP = {:.3f} ratio = {:.3f} hyp_len = {:d} ref_len = {:d})'.format(version_str, bleu.score, bleu.ngram1, bleu.ngram2, bleu.ngram3, bleu.ngram4, bleu.bp, bleu.sys_len / bleu.ref_len, bleu.sys_len, bleu.ref_len))
          
          

    
